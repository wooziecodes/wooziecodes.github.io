<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OTR Copilot: Building AI for Peer Listeners | Arif Woozeer</title>
    <meta name="description" content="I volunteered as a peer listener and kept missing emotional cues in text. So I built an AI system to help—and learned that supporting human work is harder than optimizing it.">
    <style>
        body {
            font-family: 'Helvetica', 'Arial', sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #ffffff;
            color: #000000;
        }
        .container {
            width: 80%;
            max-width: 900px;
            margin: auto;
            padding: 20px;
        }
        header {
            text-align: center;
            padding: 20px 0;
            border-bottom: 1px solid #000000;
        }
        h1 {
            font-size: 2.5em;
            margin-bottom: 0.5em;
            font-weight: 300;
        }
        nav ul {
            list-style-type: none;
            padding: 0;
        }
        nav ul li {
            display: inline;
            margin: 0 10px;
        }
        a {
            text-decoration: none;
            color: #000000;
            transition: color 0.3s ease;
        }
        a:hover {
            color: #0000ff;
        }
        .section a {
            color: #007bff;
            text-decoration: underline;
        }
        .section a:hover {
            color: #0056b3;
        }
        h2, h3, h4 {
            font-weight: 300;
        }
        .hero {
            text-align: center;
            padding: 60px 0 30px;
        }
        .hero h1 {
            font-size: 3em;
            margin-bottom: 0.3em;
            line-height: 1.2;
        }
        .hero .tagline {
            font-size: 1.3em;
            color: #666;
            margin-bottom: 15px;
        }
        .hero .meta {
            font-size: 0.95em;
            color: #999;
            margin-top: 10px;
        }
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 40px 0 50px;
        }
        .stat-box {
            padding: 25px;
            background: #f9f9f9;
            border-radius: 5px;
            text-align: center;
            border: 1px solid #eee;
        }
        .stat-number {
            font-size: 3.5em;
            font-weight: 300;
            color: #007bff;
            display: block;
            line-height: 1;
        }
        .stat-label {
            font-size: 0.9em;
            color: #666;
            margin-top: 10px;
        }
        .section {
            margin: 50px 0;
        }
        .section-divider {
            border-bottom: 1px solid #eee;
            margin: 60px 0 30px;
        }
        .hook {
            font-size: 1.2em;
            line-height: 1.7;
            color: #333;
            margin: 40px 0;
            padding: 0 20px;
        }
        .challenge-list {
            list-style: none;
            padding: 0;
            margin: 30px 0;
        }
        .challenge-list li {
            padding: 15px 0 15px 50px;
            position: relative;
            font-size: 1.05em;
            line-height: 1.6;
        }
        .challenge-list li:before {
            content: "→";
            position: absolute;
            left: 20px;
            color: #007bff;
            font-size: 1.3em;
        }
        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        .feature-card {
            padding: 25px;
            background: #fafafa;
            border-radius: 5px;
            border: 1px solid #eee;
        }
        .feature-card h4 {
            margin-top: 0;
            color: #333;
            font-size: 1.1em;
        }
        .feature-card p {
            margin: 10px 0 0;
            font-size: 0.95em;
            line-height: 1.6;
        }
        .comparison-box {
            background: linear-gradient(to bottom, #f8f9fa 50%, #e8f4f8 50%);
            padding: 40px;
            border-radius: 5px;
            margin: 30px 0;
            position: relative;
        }
        .comparison-box:before {
            content: "↓ OTR Copilot";
            position: absolute;
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%);
            background: #007bff;
            color: white;
            padding: 8px 20px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 500;
        }
        .comparison-half {
            padding: 20px;
        }
        .comparison-half h4 {
            margin-top: 0;
            margin-bottom: 15px;
        }
        .comparison-half ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }
        .comparison-half li {
            padding: 8px 0;
            font-size: 0.95em;
        }
        .comparison-half.before li:before {
            content: "✗ ";
            color: #dc3545;
            margin-right: 8px;
        }
        .comparison-half.after li:before {
            content: "✓ ";
            color: #28a745;
            margin-right: 8px;
        }
        .tech-stack {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin: 20px 0;
        }
        .tech-tag {
            padding: 8px 15px;
            background: #e9ecef;
            border-radius: 20px;
            font-size: 0.9em;
            color: #495057;
        }
        .highlight-box {
            background: #f4f8ff;
            padding: 25px;
            border-left: 4px solid #007bff;
            margin: 25px 0;
        }
        .highlight-box h4 {
            margin-top: 0;
            color: #007bff;
        }
        .highlight-box p {
            margin-bottom: 0;
        }
        .key-insight {
            background: #fff9e6;
            border-left: 4px solid #ffc107;
            padding: 25px;
            margin: 30px 0;
            font-size: 1.05em;
            line-height: 1.7;
        }
        .key-insight .insight-label {
            font-weight: 600;
            color: #f57c00;
            display: block;
            margin-bottom: 10px;
        }
        .scoping-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 30px 0;
        }
        .scoping-card {
            padding: 25px;
            border-radius: 5px;
            border: 1px solid #eee;
        }
        .scoping-card.built {
            background: #f0f8f0;
            border-color: #28a745;
        }
        .scoping-card.deferred {
            background: #fff8f0;
            border-color: #ffc107;
        }
        .scoping-card h4 {
            margin-top: 0;
        }
        .scoping-card ul {
            padding-left: 20px;
            margin: 10px 0 0;
        }
        .scoping-card li {
            padding: 5px 0;
            font-size: 0.95em;
        }
        .feedback-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        .feedback-card {
            padding: 20px;
            background: #fafafa;
            border-radius: 5px;
            border-left: 3px solid #007bff;
        }
        .feedback-card h4 {
            margin: 0 0 10px;
            font-size: 1em;
        }
        .feedback-card .quote {
            font-style: italic;
            color: #555;
            font-size: 0.9em;
            margin-bottom: 10px;
        }
        .feedback-card .implication {
            font-size: 0.85em;
            color: #666;
        }
        .links-section {
            background: #f9f9f9;
            padding: 30px;
            border-radius: 5px;
            text-align: center;
            margin: 50px 0 40px;
        }
        .links-section h2 {
            margin-top: 0;
        }
        .links-section a {
            display: inline-block;
            margin: 10px 10px;
            padding: 12px 25px;
            background: #007bff;
            color: white;
            border-radius: 5px;
            text-decoration: none;
            transition: background 0.3s ease;
        }
        .links-section a:hover {
            background: #0056b3;
        }
        @media (max-width: 768px) {
            .container {
                width: 90%;
            }
            .hero h1 {
                font-size: 2em;
            }
            .stats-grid {
                grid-template-columns: 1fr;
            }
            .scoping-grid {
                grid-template-columns: 1fr;
            }
            .comparison-box {
                padding: 30px 20px;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>Arif Woozeer</h1>
        <nav>
            <ul>
                <li><a href="about.html">About</a></li>
                <li><a href="blog.html">Writing</a></li>
                <li><a href="research.html">Research</a></li>
            </ul>
        </nav>
    </header>

    <div class="hero">
        <h1>OTR Copilot</h1>
        <p class="tagline">I spent six months as a peer listener, missing emotional cues in text messages. So I built something to help.</p>
        <p class="meta">INTS402 Capstone Project | Over The Rainbow (OTR) | January – May 2025</p>
    </div>

    <div class="container">

        <!-- The Hook -->
        <div class="hook">
            I volunteered with Over The Rainbow (OTR) as a peer listener—the person on the other end when young people in Singapore needed someone to talk to. Most of our conversations happened over text, and I kept missing things. A youth would send "sia" after a sentence, and I'd spend fifteen minutes trying to figure out if that was casual frustration or genuine distress. I'd see three messages sent at 2am, then nothing for two days, and wonder if I should've noticed the pattern sooner. I was translating emotional content across not just language but time, context, and cultural expression—and I wasn't always getting it right.
            <br><br>
            So I built an AI system to help with the parts I kept getting wrong. Not to replace the human work of listening—that's the whole point—but to catch the patterns I was missing while trying to be present for someone who needed support.
        </div>

        <div class="section-divider"></div>

        <!-- The Problem I Kept Running Into -->
        <div class="section">
            <h2>What I Kept Getting Wrong</h2>
            <p>The work of listening in text is different from listening in person. You don't have facial expressions, tone of voice, or the split-second timing of a hesitation before someone answers. Instead, you have:</p>

            <ul class="challenge-list">
                <li><strong>Messages that arrive hours apart.</strong> Someone sends "I'm fine" at noon, then three crying emojis at 2am. By the time I see it, the moment has passed. How do you track emotional shifts when the conversation is scattered across days?</li>
                <li><strong>Language that carries cultural weight I didn't always catch.</strong> Singapore youth code-switch constantly—English to Mandarin to Singlish in one sentence. A message ending in "lah" is casual. "Sia" can signal frustration, emphasis, or resignation depending on context. "Confirm plus chop" means absolute certainty, but if you're not from here, you'd miss it. I grew up between languages myself (Mauritian Creole, French, English), so I understood the <em>concept</em> of translation—but I was still learning what "walao" or "sian" actually meant to the person typing it.</li>
                <li><strong>Patterns I couldn't see while trying to stay present.</strong> I'd be focused on one conversation, trying to respond thoughtfully, while another youth I'd talked to last week was sending signals I should've noticed. I couldn't hold all the threads at once. And that bothered me, because noticing patterns—"they usually message at night, but this week it's been radio silence"—is part of good support work.</li>
            </ul>

            <p>I started wondering: could AI help with the parts I was struggling with, without turning this into something automated and cold? Could it catch the timing patterns, the cultural-linguistic cues, the cross-conversation threads—while I focused on the actual human work of being present?</p>
        </div>

        <div class="section-divider"></div>

        <!-- What I Built (Version 1) -->
        <div class="section">
            <h2>What I Built First (And What Went Wrong)</h2>

            <p>I started with what seemed logical: build a system that could do the pattern-recognition work I was struggling with. I focused on four areas:</p>

            <div class="feature-grid">
                <div class="feature-card">
                    <h4>Message timing and emotion tracking</h4>
                    <p>Analyzing when messages arrive, how long between responses, whether emoji usage changes over time—basically, all the temporal patterns I couldn't hold in my head while also trying to respond thoughtfully.</p>
                </div>

                <div class="feature-card">
                    <h4>Understanding Singapore English</h4>
                    <p>I built custom sentiment analysis that recognized "sia," "lah," "lor," "walao"—particles that carry emotional weight but get ignored by standard NLP tools trained on Western English. I pulled from linguistic research on Colloquial Singapore English and added rules for code-switching patterns.</p>
                </div>

                <div class="feature-card">
                    <h4>Response suggestions</h4>
                    <p>Using Google's Gemini 2.5 Flash to generate message templates that sounded supportive but authentic—something to help when I was staring at a blank text box at midnight, unsure how to respond to someone in distress.</p>
                </div>

                <div class="feature-card">
                    <h4>Pattern spotting across conversations</h4>
                    <p>The thing humans are genuinely bad at: noticing that three different youth all mentioned academic stress this week, or that someone's baseline communication style shifted two weeks ago.</p>
                </div>
            </div>

            <p>I built a working prototype, tested it with real mentors at OTR, and sat down to watch them use it. One tester spent about ten minutes clicking through the interface I'd carefully designed—timeline visualizations, sentiment graphs, confidence indicators, all the features I thought would be helpful.</p>

            <p>Then they looked at me and said: <strong>"This feels cold."</strong></p>

            <div class="key-insight">
                <span class="insight-label">The moment that changed everything:</span>
                Three words. "This feels cold." I had built something technically functional—it worked, it detected patterns, it generated insights. But it had turned the emotional, human work of peer listening into something that felt clinical and detached. I'd been so focused on making the AI useful that I forgot the AI was supposed to <em>support</em> a deeply human process, not optimize it.
                <br><br>
                I went back and rebuilt it. Three times.
            </div>
        </div>

        <div class="section-divider"></div>

        <!-- What I Learned About Tradeoffs -->
        <div class="section">
            <h2>What I Had to Leave Out (And Why)</h2>
            <p>I had three months and no budget. That meant making choices about what mattered most versus what would be nice to have. Some of those choices were practical. Some reflected what I'd learned from the "this feels cold" feedback.</p>

            <div class="scoping-grid">
                <div class="scoping-card built">
                    <h4>✓ What I Built</h4>
                    <ul>
                        <li>Message timing and emotion tracking</li>
                        <li>Custom Singapore English sentiment analysis</li>
                        <li>LLM-powered response suggestions</li>
                        <li>Cross-conversation pattern detection</li>
                        <li>Confidence indicators on every AI insight (so mentors know when to trust it and when to override it)</li>
                    </ul>
                </div>

                <div class="scoping-card deferred">
                    <h4>✗ What I Didn't Build</h4>
                    <ul>
                        <li>Full integration with OTR's existing platform (would've required backend access I didn't have)</li>
                        <li>Transformer-based emotion models (more accurate but harder to explain—mentors needed to understand <em>why</em> the system flagged something)</li>
                        <li>Predictive crisis detection (too risky—false positives could cause harm, false negatives could miss real crises)</li>
                        <li>Support for languages beyond English (would've needed native speakers to validate cultural-emotional nuances)</li>
                    </ul>
                </div>
            </div>

            <p><strong>The most important technical choice I made:</strong> I used rule-based NLP instead of fancy transformer models for the sentiment analysis. That sounds like a downgrade—and in terms of raw accuracy, it probably is. But here's what I realized: in a context this emotionally sensitive, mentors need to understand <em>why</em> the AI is flagging something. "The system detected frustration because the message ended in 'sia' and included three skull emojis" is something a mentor can evaluate and override if needed. "The transformer model assigned a 0.83 distress probability" is a black box. Transparency mattered more than perfect accuracy.</p>
        </div>

        <div class="section-divider"></div>

        <!-- How I Actually Built It -->
        <div class="section">
            <h2>The Technical Details</h2>

            <p>I built this using Flutter (for cross-platform mobile), Firebase for backend and auth, and Google's Gemini 2.5 Flash for the response suggestions. The custom Singapore English sentiment analysis was the hardest part—I pulled linguistic patterns from the <em>Corpus of Singapore English Messages (CoSEM)</em> and built rules for recognizing emotional weight in particles like "sia," "lah," "lor."</p>

            <div class="highlight-box">
                <h4>Why Singapore English needed custom NLP work</h4>
                <p>If you run standard sentiment analysis (trained on American or British English) on a message like "wah this assignment confirm die sia," it completely misses the emotional content. Here's what I had to teach the system to recognize:</p>
                <ul>
                    <li><strong>Sentence-final particles:</strong> "sia" (frustration/emphasis), "lah" (casual/softening), "lor" (resignation)</li>
                    <li><strong>Code-switching mid-sentence:</strong> Youth move fluidly between English, Mandarin, Malay, Tamil—sometimes within one message</li>
                    <li><strong>Localized intensifiers:</strong> "Confirm plus chop" (absolutely certain), "super" as emphasis, reduplication like "long long time"</li>
                    <li><strong>Emoji combinations with cultural meaning:</strong> Certain emoji patterns carry different emotional weight in Singapore than they do elsewhere</li>
                </ul>
                <p>This wasn't about translation. It was about recognizing that language infrastructure shapes emotional access, and if your AI doesn't understand how people actually communicate, it's useless.</p>
            </div>

            <h3>What I Built It With</h3>
            <div class="tech-stack">
                <span class="tech-tag">Flutter</span>
                <span class="tech-tag">Firebase (Auth, Firestore, Cloud Functions)</span>
                <span class="tech-tag">Google Gemini 2.5 Flash</span>
                <span class="tech-tag">Custom NLP (Singapore English)</span>
                <span class="tech-tag">JavaScript/Node.js</span>
                <span class="tech-tag">VADER Sentiment Analysis (modified)</span>
            </div>

            <h3>Timeline (Roughly)</h3>
            <ul>
                <li><strong>Mid-March:</strong> Got basic authentication and UI working</li>
                <li><strong>Early April:</strong> First version with pattern recognition and urgency detection—the one that got the "this feels cold" feedback</li>
                <li><strong>Mid-April:</strong> Rebuilt the interface twice, refined the Singapore English detection, integrated mentor feedback</li>
                <li><strong>Late April:</strong> Final user testing with 5 OTR mentors</li>
            </ul>

            <p>Privacy was non-negotiable throughout. I minimized data storage, pseudonymized everything, and made sure the system was transparent about what it could and couldn't do. This had to support human work, not surveil it.</p>
        </div>

        <div class="section-divider"></div>

        <!-- What Actually Happened When People Used It -->
        <div class="section">
            <h2>What Worked (And What Didn't)</h2>
            <p>I ran testing sessions with 5 OTR mentors—gave them pre-written conversation scenarios to work through, watched how they used the system, then sat down for honest feedback. The average rating was 3.4 out of 5, which honestly felt about right. Some things worked better than I expected. Some things I completely missed.</p>

            <h3>What Mentors Actually Said</h3>
            <div class="feedback-grid">
                <div class="feedback-card">
                    <h4>❌ Too Much Information</h4>
                    <p class="quote">"Initially overwhelming due to the amount of information."</p>
                    <p class="implication">I'd packed in every insight the system could generate, thinking more information = more helpful. Wrong. Mentors needed the system to highlight what actually mattered, not dump everything at once.</p>
                </div>

                <div class="feedback-card">
                    <h4>✓ Cross-Conversation Patterns</h4>
                    <p class="quote">"Cross-conversation pattern detection was uniquely valuable—something humans struggle with."</p>
                    <p class="implication">This was the one feature everyone agreed was genuinely useful. Turns out the thing AI is actually good at (spotting patterns across tons of data) is also the thing humans most need help with.</p>
                </div>

                <div class="feedback-card">
                    <h4>❌ Wrong Timing</h4>
                    <p class="quote">"Useful at the start, but lost effectiveness as conversations progressed."</p>
                    <p class="implication">I'd designed the system to analyze conversations upfront, then step back. But mentors needed ongoing support throughout the conversation, not just at the beginning. I'd misunderstood the workflow.</p>
                </div>

                <div class="feedback-card">
                    <h4>❌ Missing the Basics</h4>
                    <p class="quote">"Missing emoji support undermined confidence in advanced features."</p>
                    <p class="implication">I'd built sophisticated NLP for Singlish particles, but the emoji renderer was broken. Mentors (reasonably) thought: if you can't display emojis correctly, why should I trust your emotional analysis? Foundational UX quality matters more than fancy features.</p>
                </div>
            </div>

            <h3>What I Learned</h3>
            <p><strong>The AI actually helped.</strong> Mentors reported 65% improvement in interpretation accuracy when the system flagged timing patterns or cultural-linguistic cues they'd missed. The technology worked—when it wasn't overwhelming people with information.</p>

            <p><strong>Integration is everything.</strong> The system was only useful when it fit seamlessly into the mentor's existing workflow. Any friction—extra clicks, confusing navigation, having to context-switch to a different screen—meant mentors just stopped using it. "AI assistance" that disrupts your work isn't assistance.</p>

            <p><strong>Humans want to stay in control.</strong> Every mentor emphasized that they needed to make the final call, not the AI. The system that worked best was the one that showed its work (confidence indicators, explanations for why it flagged something) and deferred to human judgment. Trying to automate away the human decision-making completely missed the point of what peer support actually is.</p>
        </div>

        <div class="section-divider"></div>

        <!-- What This Taught Me About Building AI for People -->
        <div class="section">
            <h2>What This Actually Taught Me</h2>
            <p>I came into this project with a technical background (Information Systems major—I knew how to build things with Flutter, Firebase, NLP) and a second major in College of Integrative Studies (CIS), which focuses on asking better questions about technology, culture, and power. I thought I understood how those two perspectives fit together. Building OTR Copilot showed me I didn't, really—at least not in practice.</p>

            <p>The technical part was straightforward: sentiment analysis, pattern recognition, LLM integration. The hard part was figuring out what I was actually trying to build. Was this a tool to make mentors more efficient? Was it about catching emotional signals they were missing? Was it about reducing cognitive load? All of those sounded reasonable, but they led to different design choices—and some of those choices turned the work into something "cold" and clinical.</p>

            <p>Here's what I learned: <strong>building AI that supports human work without replacing it is not a technical problem. It's a question about what human work actually is.</strong> Peer listening isn't just pattern recognition (even though patterns matter). It's relationship-building, trust formation, being present with someone in distress. If you optimize for the pattern recognition and accidentally undermine the relationship-building, you've made things worse, not better.</p>

            <p>Every technical choice I made carried assumptions about what mattered:</p>
            <ul>
                <li><strong>Choosing rule-based NLP over transformer models</strong> wasn't about accuracy—it was about trust. Mentors needed to understand <em>why</em> the system flagged something, not just accept a black-box probability score.</li>
                <li><strong>Building custom Singapore English detection</strong> wasn't just localization—it was recognizing that language infrastructure shapes who gets access to emotional support. If your AI doesn't understand how people actually talk, it's useless (or worse, it's harmful).</li>
                <li><strong>Adding confidence indicators to every insight</strong> was about keeping humans in control. The AI suggests; the mentor decides. That's not a nice-to-have feature—it's the whole point.</li>
            </ul>

            <p>My CIS coursework kept asking: what does human flourishing look like in a world full of ambient intelligence? What does agency mean when AI systems mediate emotional, economic, cognitive life? Those questions sounded abstract in class. They became very concrete when a mentor looked at my interface and said "this feels cold." That's the moment theory becomes practice—when you realize the AI you built might be technically functional but existentially wrong.</p>

            <div class="key-insight">
                <span class="insight-label">The thing I'll carry forward:</span>
                Technology that supports human work has to be built <em>with</em> an understanding of what that work actually is—not what you think it should be, not what would be technically impressive, but what the people doing the work say they need. That sounds obvious. It's not. It took three complete redesigns for me to really understand it.
            </div>
        </div>

        <div class="section-divider"></div>

        <!-- Links & Resources -->
        <div class="links-section">
            <h2>Explore the Project</h2>
            <div>
                <a href="https://github.com/wooziecodes/otr-copilot" target="_blank">View on GitHub</a>
                <a href="https://youtu.be/demo-link" target="_blank">Watch Demo Video</a>
                <a href="./assets/pdf/otr-capstone-report.pdf" target="_blank">Download Full Report (PDF)</a>
                <a href="research.html">← Back to Research</a>
            </div>
        </div>

    </div>
</body>
</html>